import torch
import torch.nn as nn
from torch.utils.data import DataLoader
import wandb
from pathlib import Path
import sys
import time
from torchvision.utils import make_grid
import numpy as np
from skimage.metrics import peak_signal_noise_ratio as psnr
from skimage.metrics import structural_similarity as ssim
from typing import Tuple, Union
from tqdm import tqdm # **å…³é”®ä¿®æ­£**: å¯¼å…¥tqdmåº“
from models.ssl_unet_autoencoder import UNetAutoencoder
import matplotlib.pyplot as plt
import os
from utils.training_util import SSIMLoss, VGGPerceptualLoss
import random
from utils.logging_util import Logger

# --- é…ç½®ä¸æ¨¡å—å¯¼å…¥ ---
try:
    from configs import base as cfg_base
    from configs.selfup import ssl_config as cfg_ssl
    from configs import wandb_config as cfg_wandb
    from datasets.ssl_dataset import SSLDataset
    from models.ssl_mae_model import MaskedAutoencoderUNet
except ImportError as e:
    print(f"å¯¼å…¥æ¨¡å—æ—¶å‡ºé”™: {e}")
    if __name__ == '__main__' and __package__ is None:
        current_script_path = Path(__file__).resolve()
        project_root = current_script_path.parent.parent
        sys.path.insert(0, str(project_root))
        from configs import base as cfg_base
        from configs.selfup import ssl_config as cfg_ssl
        from configs import wandb_config as cfg_wandb
        from datasets.ssl_dataset import SSLDataset
        from models.ssl_mae_model import MaskedAutoencoderUNet
    else:
        raise

SEED = getattr(cfg_ssl, 'SEED', 42)  # ä»configè¯»å–å…¨å±€éšæœºç§å­
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
# è‹¥åç»­æœ‰albumentationså®˜æ–¹set_seedæ–¹æ³•å¯ç”¨ï¼Œå¯è¡¥å……

def create_encoder(encoder_name: str) -> nn.Module:
    """
    æ ¹æ®é…ç½®åŠ¨æ€åˆ›å»ºç¼–ç å™¨å®ä¾‹ã€‚
    """
    print(f"--- æ­£åœ¨åˆ›å»ºç¼–ç å™¨: {encoder_name} ---")
    
    if encoder_name == 'unet':
        from models.encoders.unet_encoder import UNetEncoder
        encoder = UNetEncoder(n_channels=1)
    # åœ¨è¿™é‡Œå¯ä»¥ç»§ç»­æ·»åŠ å…¶ä»–ç¼–ç å™¨çš„ 'elif' åˆ†æ”¯
    # elif encoder_name == 'resnet50':
    #     from models.encoders.resnet_encoder import ResNetEncoder
    #     encoder = ResNetEncoder(name='resnet50', in_channels=1, weights=None)
    else:
        raise ValueError(f"æœªçŸ¥çš„ç¼–ç å™¨åç§°: '{encoder_name}'")
    return encoder

def evaluate_reconstruction_metrics(model, dataloader, device) -> Tuple[float, float]:
    """è¯„ä¼°é‡å»ºè´¨é‡çš„PSNRå’ŒSSIMæŒ‡æ ‡"""
    model.eval()
    total_psnr, total_ssim, num_samples = 0.0, 0.0, 0
    
    with torch.no_grad():
        for masked_images, original_images, loss_masks in dataloader:
            # SSLæ•°æ®é›†è¿”å›: (masked_images, original_images, loss_masks)
            masked_images = masked_images.to(device)
            original_images_cpu = original_images.numpy()
            reconstructed_images = model(masked_images).cpu().numpy()
            
            for i in range(original_images_cpu.shape[0]):
                # è·å–åŸå§‹å›¾åƒå’Œé‡å»ºå›¾åƒ
                ori_img = np.squeeze(original_images_cpu[i])
                rec_img = np.squeeze(reconstructed_images[i])
                
                # ç¡®ä¿å›¾åƒåœ¨æ­£ç¡®çš„èŒƒå›´å†…
                if ori_img.max() > 1.0:
                    ori_img = ori_img / 255.0
                if rec_img.max() > 1.0:
                    rec_img = rec_img / 255.0
                
                # è®¡ç®—PSNR
                data_range = ori_img.max() - ori_img.min()
                if data_range == 0: 
                    data_range = 1.0
                
                try:
                    psnr_val = psnr(ori_img, rec_img, data_range=data_range)
                    if isinstance(psnr_val, tuple):
                        psnr_val = psnr_val[0]
                    total_psnr += float(psnr_val)
                except Exception as e:
                    print(f"PSNRè®¡ç®—é”™è¯¯: {e}")
                    total_psnr += 0.0
                
                # è®¡ç®—SSIM
                try:
                    ssim_val = ssim(ori_img, rec_img, data_range=data_range)
                    if isinstance(ssim_val, tuple):
                        ssim_val = ssim_val[0]
                    total_ssim += float(ssim_val)
                except Exception as e:
                    print(f"SSIMè®¡ç®—é”™è¯¯: {e}")
                    total_ssim += 0.0
                    
            num_samples += original_images_cpu.shape[0]
    
    # è®¡ç®—å¹³å‡å€¼
    avg_psnr = total_psnr / num_samples if num_samples > 0 else 0.0
    avg_ssim = total_ssim / num_samples if num_samples > 0 else 0.0
    
    return avg_psnr, avg_ssim

def visualize_ssl_batch(masked_images, original_images, reconstructed_images, loss_masks, save_dir, prefix="epoch", max_samples=8):
    os.makedirs(save_dir, exist_ok=True)
    masked_images = masked_images.cpu().numpy()
    original_images = original_images.cpu().numpy()
    reconstructed_images = reconstructed_images.cpu().numpy()
    loss_masks = loss_masks.cpu().numpy()
    n = min(max_samples, masked_images.shape[0])
    for i in range(n):
        fig, axs = plt.subplots(1, 4, figsize=(12, 3))
        axs[0].imshow(original_images[i][0], cmap="gray")
        axs[0].set_title("Original")
        axs[1].imshow(masked_images[i][0], cmap="gray")
        axs[1].set_title("Masked Input")
        axs[2].imshow(reconstructed_images[i][0], cmap="gray")
        axs[2].set_title("Reconstructed")
        axs[3].imshow(loss_masks[i], cmap="gray")
        axs[3].set_title("Mask Area")
        for ax in axs:
            ax.axis("off")
        plt.tight_layout()
        plt.savefig(os.path.join(save_dir, f"{prefix}_sample_{i}.png"))
        plt.close(fig)

def train_ssl_mae():
    project_root = cfg_base.PROJECT_ROOT.resolve()
    # ä¿®å¤è®¾å¤‡æ£€æµ‹
    if torch.cuda.is_available():
        device = torch.device("cuda")
        print(f"CUDA å¯ç”¨ï¼Œä½¿ç”¨ GPU: {torch.cuda.get_device_name()}")
    else:
        device = torch.device("cpu")
        print("CUDA ä¸å¯ç”¨ï¼Œä½¿ç”¨ CPU")
    
    print(f"--- å¼€å§‹è‡ªç›‘ç£é¢„è®­ç»ƒä»»åŠ¡: {cfg_ssl.MODEL_NAME} ---")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")

    # ç§»é™¤ wandb.init() å’Œ wandb.watch()
    # wandb.init(
    #     project=cfg_wandb.PROJECT_NAME_SSL,
    #     name=f"ssl-{cfg_ssl.MODEL_NAME}-{int(time.time())}",
    #     mode=cfg_wandb.WANDB_MODE,
    #     config={
    #         "encoder": cfg_ssl.ENCODER_NAME,
    #         "learning_rate": cfg_ssl.LEARNING_RATE,
    #         "epochs": cfg_ssl.NUM_EPOCHS,
    #         "batch_size": cfg_ssl.BATCH_SIZE,
    #         # "patch_size": cfg_ssl.PATCH_SIZE,  # å·²åˆ é™¤
    #         "mask_ratio": cfg_ssl.MASK_RATIO,
    #     }
    # )
    # if wandb.run is not None:
    #     print(f"Wandb åœ¨ '{getattr(wandb.run, 'mode', 'unknown')}' æ¨¡å¼ä¸‹åˆå§‹åŒ–ã€‚")
    # else:
    #     print("Wandb æœªå¯ç”¨æˆ–åˆå§‹åŒ–å¤±è´¥ã€‚")

    json_path = project_root / cfg_ssl.JSON_DIR_NAME / cfg_ssl.UNLABELED_JSON_NAME
    ssl_dataset = SSLDataset(json_file_path=json_path, project_root=project_root)
    ssl_loader = DataLoader(ssl_dataset, batch_size=cfg_ssl.BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True, drop_last=True)
    vis_loader = DataLoader(ssl_dataset, batch_size=8, shuffle=True)
    vis_batch = next(iter(vis_loader)) if len(vis_loader) > 0 else None

    # encoder = create_encoder(cfg_ssl.ENCODER_NAME)
    # model = MaskedAutoencoderUNet(
    #     encoder=encoder,
    #     decoder_embed_dim=cfg_ssl.DECODER_EMBED_DIM,
    #     n_channels_in=1
    # ).to(device)
    model = UNetAutoencoder(n_channels=1, n_classes=1).to(device)
    
    # æŸå¤±å‡½æ•°ç»„åˆï¼šMSE + SSIM + æ„ŸçŸ¥
    mse_criterion = nn.MSELoss(reduction='none')
    ssim_criterion = SSIMLoss(window_size=11)
    perceptual_criterion = VGGPerceptualLoss(resize=True)
    def combined_ssl_loss(pred, target, mask):
        # mask: (B, H, W) or (B, 1, H, W)
        mask_exp = mask.unsqueeze(1) if mask.dim() == 3 else mask
        mse = (mse_criterion(pred, target) * mask_exp).sum() / mask_exp.sum().clamp(min=1e-5)
        # SSIMå’Œæ„ŸçŸ¥æŸå¤±ä¸åŠ maskï¼ˆå¯é€‰åŠ æƒï¼‰
        ssim = ssim_criterion(pred, target)
        perceptual = perceptual_criterion(pred, target)
        return mse + 0.5 * ssim + 0.1 * perceptual
    
    optimizer = torch.optim.AdamW(model.parameters(), lr=cfg_ssl.LEARNING_RATE, weight_decay=cfg_ssl.WEIGHT_DECAY)
    
    # ç§»é™¤ wandb.run is not None and getattr(wandb.run, 'mode', None) != "disabled" çš„æ£€æŸ¥
    # if wandb.run is not None and getattr(wandb.run, 'mode', None) != "disabled":
    #     wandb.watch(model, log="all", log_freq=100)
    
    checkpoint_dir = project_root / cfg_ssl.SSL_CHECKPOINT_DIR
    checkpoint_dir.mkdir(parents=True, exist_ok=True)
    
    start_epoch = 0
    best_loss = float('inf') 
    resumable_checkpoint_path = project_root / cfg_ssl.RESUMABLE_CHECKPOINT_PATH
    if cfg_ssl.RESUME_FROM_CHECKPOINT and resumable_checkpoint_path.exists():
        print(f"æ­£åœ¨ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ: {resumable_checkpoint_path}")
        checkpoint = torch.load(resumable_checkpoint_path, map_location=device)
        model.load_state_dict(checkpoint['model_state_dict'])
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        start_epoch = checkpoint.get('epoch', 0) + 1
        best_loss = checkpoint.get('best_loss', float('inf'))
        print(f"å·²ä» epoch {start_epoch-1} æ¢å¤ã€‚ç›®å‰æœ€ä½³æŸå¤±: {best_loss:.6f}ã€‚")
    else:
        print("ä»å¤´å¼€å§‹è®­ç»ƒã€‚")

    print(f"å°†ä» Epoch {start_epoch + 1} å¼€å§‹è®­ç»ƒ...")
    logger = Logger(cfg_ssl.log_config)
    for epoch in range(start_epoch, cfg_ssl.NUM_EPOCHS):
        model.train()
        total_loss = 0.0
        progress_bar = tqdm(ssl_loader, desc=f"Epoch {epoch+1}/{cfg_ssl.NUM_EPOCHS}", leave=False)
        for masked_images, original_images, loss_masks in progress_bar:
            masked_images, original_images, loss_masks = masked_images.to(device), original_images.to(device), loss_masks.to(device)
            optimizer.zero_grad()
            reconstructed_images = model(masked_images)
            #loss_masks_expanded = loss_masks.unsqueeze(1)
            #per_pixel_loss = criterion(reconstructed_images, original_images)
            #loss = (per_pixel_loss * loss_masks_expanded).sum() / loss_masks_expanded.sum().clamp(min=1e-5)
            loss = combined_ssl_loss(reconstructed_images, original_images, loss_masks)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
            progress_bar.set_postfix(loss=loss.item())
        # --- å¯è§†åŒ–è°ƒè¯•: æ¯ä¸ªepochä¿å­˜ä¸€æ‰¹æ ·æœ¬ ---
        if (epoch + 1) % 1 == 0:  # å¯æŒ‰éœ€è°ƒæ•´é¢‘ç‡
            model.eval()
            with torch.no_grad():
                vis_masked, vis_original, vis_loss_mask = next(iter(vis_loader))
                vis_masked = vis_masked.to(device)
                vis_original = vis_original.to(device)
                vis_loss_mask = vis_loss_mask.to(device)
                vis_reconstructed = model(vis_masked)
                visualize_ssl_batch(
                    vis_masked, vis_original, vis_reconstructed, vis_loss_mask,
                    save_dir=str(project_root / "data" / "ssl_debug_vis"),
                    prefix=f"epoch{epoch+1}", max_samples=8
                )
            model.train()

        avg_loss = total_loss / len(ssl_loader)
        
        # === æ¯ä¸ªepochéƒ½è¯„ä¼°PSNRå’ŒSSIM ===
        model.eval()
        with torch.no_grad():
            avg_psnr, avg_ssim = evaluate_reconstruction_metrics(model, vis_loader, device)
        model.train()
        
        # æ‰“å°æ¯ä¸ªepochçš„è¯¦ç»†æŒ‡æ ‡
        print(f"Epoch [{epoch+1}/{cfg_ssl.NUM_EPOCHS}], "
              f"å¹³å‡é‡å»ºæŸå¤±: {avg_loss:.6f}, "
              f"Validation PSNR: {avg_psnr:.4f} dB, "
              f"SSIM: {avg_ssim:.4f}")

        # æ„å»ºå®Œæ•´çš„æ—¥å¿—å­—å…¸
        log_dict = {
            "epoch": epoch + 1,
            "ssl_loss": avg_loss,
            "val_psnr": avg_psnr,
            "val_ssim": avg_ssim,
            "learning_rate": optimizer.param_groups[0]['lr']
        }
        is_best = avg_loss < best_loss
        if is_best:
            best_loss = avg_loss
            print(f"  -> æ–°çš„æœ€ä½³æŸå¤±è®°å½•: {best_loss:.6f}")
            
        # è®°å½•æœ€ä½³PSNRå’ŒSSIM
        if not hasattr(model, 'best_psnr'):
            model.best_psnr = 0.0
        if not hasattr(model, 'best_ssim'):
            model.best_ssim = 0.0
            
        if avg_psnr > model.best_psnr:
            model.best_psnr = avg_psnr
            print(f"  -> æ–°çš„æœ€ä½³PSNRè®°å½•: {model.best_psnr:.4f} dB")
            
        if avg_ssim > model.best_ssim:
            model.best_ssim = avg_ssim
            print(f"  -> æ–°çš„æœ€ä½³SSIMè®°å½•: {model.best_ssim:.4f}")
            
        # æ›´æ–°æ—¥å¿—å­—å…¸ï¼ŒåŒ…å«æœ€ä½³æŒ‡æ ‡
        log_dict.update({
            "best_loss": best_loss,
            "best_psnr": model.best_psnr,
            "best_ssim": model.best_ssim
        })

        if (epoch + 1) % cfg_ssl.SAVE_BEST_CHECK_EVERY_N_EPOCHS == 0 or (epoch + 1) == cfg_ssl.NUM_EPOCHS:
            if is_best:
                best_model_path = project_root / cfg_ssl.BEST_MODEL_CHECKPOINT_PATH
                print(f"  -> æ­£åœ¨ä¿å­˜ epoch {epoch+1} çš„æœ€ä½³æ¨¡å‹ç¼–ç å™¨è‡³ {best_model_path}...")
                torch.save(model.encoder.state_dict(), best_model_path)
                # ç§»é™¤ wandb.run is not None and getattr(wandb.run, 'mode', None) != "disabled" çš„æ£€æŸ¥
                # if wandb.run is not None and getattr(wandb.run, 'mode', None) != "disabled":
                #     wandb.save(str(best_model_path)) 
            
            if vis_batch and vis_batch is not None: # ç¡®ä¿ vis_batch ä¸ä¸º None
                model.eval()
                with torch.no_grad():
                    vis_masked, vis_original, _ = vis_batch
                    vis_reconstructed = model(vis_masked.to(device)).cpu()
                    grid_original = make_grid(vis_original, nrow=4, normalize=True)
                    grid_masked = make_grid(vis_masked, nrow=4, normalize=True)
                    grid_reconstructed = make_grid(vis_reconstructed, nrow=4, normalize=True)
                    log_dict["visualizations/original"] = wandb.Image(grid_original)
                    log_dict["visualizations/masked"] = wandb.Image(grid_masked)
                    log_dict["visualizations/reconstructed"] = wandb.Image(grid_reconstructed)
                
                # è¿™é‡Œä¸éœ€è¦é‡å¤è¯„ä¼°ï¼Œå› ä¸ºå·²ç»åœ¨ä¸Šé¢è¯„ä¼°è¿‡äº†
                # åªéœ€è¦è®°å½•å¯è§†åŒ–ç»“æœ
                pass

        torch.save({
            'epoch': epoch, 'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(), 'loss': avg_loss, 'best_loss': best_loss,
        }, resumable_checkpoint_path)
        
        # ç§»é™¤ wandb.run is not None and getattr(wandb.run, 'mode', None) != "disabled" çš„æ£€æŸ¥
        # if wandb.run is not None and getattr(wandb.run, 'mode', None) != "disabled":
        #     wandb.log(log_dict)
        logger.log(log_dict, step=epoch+1)
    logger.close()

    final_encoder_path = project_root / cfg_ssl.SSL_ENCODER_FINAL_PATH
    torch.save(model.encoder.state_dict(), final_encoder_path)
    # ç§»é™¤ wandb.run is not None and getattr(wandb.run, 'mode', None) != "disabled" çš„æ£€æŸ¥
    # if wandb.run is not None and getattr(wandb.run, 'mode', None) != "disabled":
    #     wandb.save(str(final_encoder_path))
    #     wandb.finish()
    
    print(f"è®­ç»ƒç»“æŸã€‚æœ€ç»ˆSSLé¢„è®­ç»ƒç¼–ç å™¨å·²ä¿å­˜è‡³ {final_encoder_path}")
    
    # æ‰“å°è®­ç»ƒæ€»ç»“
    print("\n" + "="*60)
    print("ğŸ¯ SSLé¢„è®­ç»ƒè®­ç»ƒæ€»ç»“")
    print("="*60)
    print(f"æ€»è®­ç»ƒè½®æ¬¡: {cfg_ssl.NUM_EPOCHS}")
    print(f"æœ€ç»ˆé‡å»ºæŸå¤±: {avg_loss:.6f}")
    print(f"æœ€ä½³é‡å»ºæŸå¤±: {best_loss:.6f}")
    print(f"æœ€ç»ˆéªŒè¯PSNR: {avg_psnr:.4f} dB")
    print(f"æœ€ä½³éªŒè¯PSNR: {model.best_psnr:.4f} dB")
    print(f"æœ€ç»ˆéªŒè¯SSIM: {avg_ssim:.4f}")
    print(f"æœ€ä½³éªŒè¯SSIM: {model.best_ssim:.4f}")
    print("="*60)

    # æ–°å¢ï¼šè®­ç»ƒ-è¯„ä¼°å¯¹æ¯”å¯è§†åŒ–ï¼ˆä¸inspectä¸€è‡´ï¼‰
    compare_dir = project_root / "data" / "ssl_compare"
    compare_dir.mkdir(parents=True, exist_ok=True)
    compare_idx = 290
    print(f"[å¯¹æ¯”æ¨¡å¼] è®­ç»ƒè„šæœ¬ä¿å­˜ç´¢å¼• {compare_idx} çš„å¯è§†åŒ–ç»“æœ")
    masked_img, original_img, loss_mask = ssl_dataset[compare_idx]
    masked_img_tensor = masked_img.unsqueeze(0).to(device)
    with torch.no_grad():
        recon_img = model(masked_img_tensor).cpu().numpy()[0, 0]
    import matplotlib.pyplot as plt
    plt.imsave(compare_dir / "train_masked.png", masked_img[0], cmap="gray")
    plt.imsave(compare_dir / "train_mask.png", loss_mask, cmap="gray")
    plt.imsave(compare_dir / "train_recon.png", recon_img, cmap="gray")
    plt.imsave(compare_dir / "train_original.png", original_img[0], cmap="gray")
    print(f"[å¯¹æ¯”æ¨¡å¼] å·²ä¿å­˜è®­ç»ƒMasked Inputã€Mask Areaã€Reconstructedã€Originalåˆ°: {compare_dir}")

if __name__ == '__main__':
    train_ssl_mae()